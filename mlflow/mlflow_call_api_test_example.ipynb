{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6139a304",
   "metadata": {},
   "source": [
    "# Mlflow call api Evaluation Instructions\n",
    "\n",
    "This Jupyter notebook ([mlflow_call_api_test_example.ipynb](file:///Users/jlkj/study/LLM_Evaluation/mlflow/mlflow_call_api_test_example.ipynb)) is designed to evaluate an ECG (electrocardiogram) recognition API using MLflow's generative AI evaluation capabilities. Below is a detailed instruction on how to use this notebook:\n",
    "\n",
    "## Overview\n",
    "\n",
    "The notebook performs the following tasks:\n",
    "1. Sets up MLflow tracking for experiment management\n",
    "2. Defines utility functions for handling image data and JSON files\n",
    "3. Creates a function to call the ECG recognition API\n",
    "4. Implements a custom scorer to evaluate API results\n",
    "5. Runs evaluation on a dataset of ECG images with expected results\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python environment with required packages: `mlflow`, `requests`, `base64`, `json`\n",
    "- Access to MLflow tracking server at `http://192.168.100.30:5000`\n",
    "- Access to ECG recognition API at `http://192.168.100.24:9004/api/jl-hospital/ecg_recog`\n",
    "- Dataset of ECG images in `./data/xindiantu/` directory\n",
    "- Annotated dataset file at `annotated_data/ecg_dataset_annotated.json`\n",
    "\n",
    "## Step-by-Step Instructions\n",
    "\n",
    "### 1. Environment Setup\n",
    "The first cell initializes MLflow tracking:\n",
    "- Connects to the MLflow tracking server\n",
    "- Sets up an experiment named \"ecg_recog\"\n",
    "- Tags the run as \"ecg api test\"\n",
    "\n",
    "### 2. Utility Functions\n",
    "Two helper functions are defined:\n",
    "- `image_to_base64(image_path)`: Converts JPG images to base64 encoded strings for API transmission\n",
    "- `read_json_file(file_path)`: Reads and parses JSON data files\n",
    "\n",
    "### 3. API Calling Function\n",
    "The `call_ecg_api(image, **kwargs)` function:\n",
    "- Takes an image filename as input\n",
    "- Converts the image to base64 format\n",
    "- Sends a POST request to the ECG recognition API\n",
    "- Returns the JSON response from the API\n",
    "\n",
    "### 4. Custom Scoring Function\n",
    "The `ecg_result_match` scorer:\n",
    "- Compares API outputs with expected results\n",
    "- Calculates a score based on matching of 8 ECG parameters\n",
    "- Returns a normalized score between 0 and 1\n",
    "\n",
    "### 5. Dataset Loading\n",
    "Loads the annotated ECG dataset from `ecg_dataset_annotated.json`.\n",
    "\n",
    "### 6. Evaluation Execution\n",
    "Runs the evaluation process:\n",
    "- Uses `mlflow.genai.evaluate()` to test the API\n",
    "- Iterates through all samples in the dataset\n",
    "- Applies the custom scorer to compare results\n",
    "- Logs metrics and results to MLflow\n",
    "\n",
    "## Expected Output\n",
    "\n",
    "After running the evaluation:\n",
    "- You'll see printed comparisons between API outputs and expected values\n",
    "- A final evaluation result showing the mean score (e.g., 0.99)\n",
    "- Results will be viewable in the MLflow UI via the provided link\n",
    "\n",
    "## Customization\n",
    "\n",
    "To adapt this notebook for your use:\n",
    "1. Update MLflow tracking URI if needed\n",
    "2. Modify API endpoint URL\n",
    "3. Adjust the scoring function based on your specific evaluation criteria\n",
    "4. Update dataset paths as needed\n",
    "\n",
    "The current implementation achieves ~99% accuracy on the ECG parameter matching task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830145d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.genai import scorer\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://192.168.100.30:5000\")\n",
    "mlflow.set_experiment(\"ecg_recog\")\n",
    "\n",
    "# set each experiment run name\n",
    "mlflow.set_tag(\"mlflow.runName\", \"ecg api test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a83db3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image to Base64 function\n",
    "import base64\n",
    "\n",
    "def image_to_base64(image_path):\n",
    "    \"\"\"\n",
    "    Convert a JPG image file to base64 encoded string\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the JPG image file\n",
    "        \n",
    "    Returns:\n",
    "        str: Base64 encoded string of the image\n",
    "    \"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read())\n",
    "        return encoded_string.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c501564",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read JSON File\n",
    "import json\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    \"\"\"\n",
    "    Read and parse JSON data from a file\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the JSON file\n",
    "        \n",
    "    Returns:\n",
    "        dict or list: Parsed JSON data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "        return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error: Invalid JSON format in '{file_path}': {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file '{file_path}': {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f653d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def call_ecg_api(image: str, **kwargs) -> str:\n",
    "    API_URL = \"http://192.168.100.24:9004/api/jl-hospital/ecg_recog\"  ## ecg_recog api endpoint\n",
    "    HEADERS = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    image_path = f'./data/xindiantu/{image}'\n",
    "    image_base64 = image_to_base64(image_path)\n",
    "    input_json = {\"imageUrl\": image_base64}\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            API_URL,\n",
    "            headers=HEADERS,\n",
    "            json=input_json,\n",
    "            timeout=100\n",
    "        )\n",
    "        response.raise_for_status()  # 检查HTTP错误\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"API调用失败: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b657d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## difine scorer function\n",
    "@scorer\n",
    "def ecg_result_match(outputs: str, expectations: dict) -> bool:\n",
    "    print(f\"outputs: {outputs}, expectations: {expectations}\")\n",
    "    score = 0\n",
    "    try:\n",
    "        if outputs['HeartRate'] == expectations[\"expected_response\"][\"HeartRate\"]:\n",
    "            score += 1\n",
    "        if outputs['PR_Interval'] == expectations[\"expected_response\"][\"PR_Interval\"]:\n",
    "            score += 1\n",
    "        if outputs['QRS_Duration'] == expectations[\"expected_response\"][\"QRS_Duration\"]:\n",
    "            score += 1\n",
    "        if outputs['QT'] == expectations[\"expected_response\"][\"QT\"]:\n",
    "            score += 1\n",
    "        if outputs['QTc'] == expectations[\"expected_response\"][\"QTc\"]:\n",
    "            score += 1\n",
    "        if outputs['AXIS'] == expectations[\"expected_response\"][\"AXIS\"]:\n",
    "            score += 1\n",
    "        if outputs['RV5'] == expectations[\"expected_response\"][\"RV5\"]:\n",
    "            score += 1\n",
    "        if outputs['SV1'] == expectations[\"expected_response\"][\"SV1\"]:\n",
    "            score += 1\n",
    "        \n",
    "        final_score = score / 8\n",
    "    except:\n",
    "        return (False, f\"Error{e}\")\n",
    "    \n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35a4fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_json_file(\"annotated_data/ecg_dataset_annotated.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1decef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = mlflow.genai.evaluate(\n",
    "            data=dataset,\n",
    "            predict_fn=call_ecg_api,\n",
    "            scorers=[ecg_result_match\n",
    "            ],\n",
    "        )\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19922c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "\n",
    "## Set models\n",
    "MODEL_NAME   = 'qwen3'\n",
    "LLM_API_BASE = \"http://192.168.100.30:16001/v1\"\n",
    "MAX_TOKENS   = 2048\n",
    "TIME_OUT     = 600\n",
    "\n",
    "Settings.llm = OpenAILike(\n",
    "            model=MODEL_NAME,\n",
    "            api_base=LLM_API_BASE,\n",
    "            api_key='EMPTY',\n",
    "            is_chat_model=True,\n",
    "            temperature=0.6,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            timeout=TIME_OUT,\n",
    "            additional_kwargs={\"extra_body\": {\"chat_template_kwargs\": {\"enable_thinking\": False}}},\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c87cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.genai import scorer\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"prompt_test\")\n",
    "mlflow.set_tag(\"mlflow.runName\", \"prompt_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c073458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_function(question: str, **kwargs) -> str:\n",
    "    ## choose a prompt\n",
    "    ## Set up in mlflow before running\n",
    "    prompt = mlflow.genai.load_prompt(\"prompts:/test_prompt_1/3\")\n",
    "    user_prompt = question\n",
    "    messages = [\n",
    "        ChatMessage(role=\"assistant\", content=prompt.format()),\n",
    "        ChatMessage(role=\"user\", content=user_prompt)\n",
    "    ]\n",
    "    response = Settings.llm.chat(messages, **kwargs)\n",
    "    print(f\"response: {response.message.blocks[0].text}\")\n",
    "    return response.message.blocks[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d93e3eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "@scorer\n",
    "def exact_match(outputs: str, expectations: dict) -> bool:\n",
    "    print(f\"outputs: {outputs}, expectations: {expectations}\")\n",
    "    return outputs == expectations[\"expected_response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162e3211",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "            {\n",
    "                \"inputs\": {\"question\": \"My fasting blood glucose is 10 mmol, do I have diabetes risk?\"},\n",
    "                \"expectations\": {\"expected_response\": \"Yes.\"},\n",
    "            },\n",
    "            {\n",
    "                \"inputs\": {\"question\": \"I have a headache, am I going to die soon?\"},\n",
    "                \"expectations\": {\n",
    "                    \"expected_response\": \"No.\"\n",
    "                },\n",
    "            },\n",
    "            {\n",
    "                \"inputs\": {\"question\": \"My blood pressure is 150/110, do I have hypertension risk?\"},\n",
    "                \"expectations\": {\n",
    "                    \"expected_response\": \"Yes.\"\n",
    "                },\n",
    "            },\n",
    "            {\n",
    "                \"inputs\": {\"question\": \"My heart beats 60 times per minute, is my heartbeat abnormal?\"},\n",
    "                \"expectations\": {\n",
    "                    \"expected_response\": \"No.\"\n",
    "                },\n",
    "            },\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee22b30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = mlflow.genai.evaluate(\n",
    "            data=dataset,\n",
    "            predict_fn=llm_function,\n",
    "            scorers=[exact_match\n",
    "            ],\n",
    "        )\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5c8274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/dev/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "class ModelBenchmark:\n",
    "    def __init__(self, model_configs: Dict[str, Dict[str, Any]]):\n",
    "        \"\"\"\n",
    "        初始化模型基准测试类\n",
    "        \n",
    "        Args:\n",
    "            model_configs: 模型配置字典，格式为 {\n",
    "                \"model_name_1\": {\"api_base\": \"http://localhost:8001\", \"api_key\": \"empty\"},\n",
    "                \"model_name_2\": {\"api_base\": \"http://localhost:8002\", \"api_key\": \"empty\"}\n",
    "            }\n",
    "        \"\"\"\n",
    "        self.models = {}\n",
    "        for model_name, config in model_configs.items():\n",
    "            self.models[model_name] = OpenAILike(\n",
    "                model=model_name,\n",
    "                api_base=config[\"api_base\"],\n",
    "                api_key=config.get(\"api_key\", \"sk-xxx\"),\n",
    "                is_chat_model=True,\n",
    "                max_retries=3,\n",
    "                timeout=100,\n",
    "                additional_kwargs={\"extra_body\": {\"chat_template_kwargs\": {\"enable_thinking\": False}}}\n",
    "            )\n",
    "    \n",
    "    def create_test_messages(self, prompt: str) -> List[ChatMessage]:\n",
    "        \"\"\"创建测试对话消息\"\"\"\n",
    "        return [\n",
    "            ChatMessage(role=\"system\", content=\"你是一个有帮助的AI助手。\"),\n",
    "            ChatMessage(role=\"user\", content=prompt)\n",
    "        ]\n",
    "    \n",
    "    async def test_single_model(self, model_name: str, prompt: str, num_runs: int = 5) -> Dict[str, Any]:\n",
    "        \"\"\"测试单个模型的性能\"\"\"\n",
    "        print(f\"正在测试模型: {model_name}\")\n",
    "        \n",
    "        results = {\n",
    "            \"model\": model_name,\n",
    "            \"total_time\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"response_times\": [],\n",
    "            \"throughputs\": [],\n",
    "            \"success_count\": 0\n",
    "        }\n",
    "        \n",
    "        messages = self.create_test_messages(prompt)\n",
    "        \n",
    "        for i in range(num_runs):\n",
    "            try:\n",
    "                start_time = time.time()\n",
    "                response = await self.models[model_name].acomplete(\n",
    "                    prompt,\n",
    "                    messages\n",
    "                )\n",
    "                \n",
    "                end_time = time.time()\n",
    "                elapsed_time = end_time - start_time\n",
    "                \n",
    "                # 计算token数量（近似值）\n",
    "                tokens = len(response.text.split())\n",
    "                \n",
    "                results[\"total_time\"] += elapsed_time\n",
    "                results[\"total_tokens\"] += tokens\n",
    "                results[\"response_times\"].append(elapsed_time)\n",
    "                results[\"throughputs\"].append(tokens / elapsed_time)\n",
    "                results[\"success_count\"] += 1\n",
    "                \n",
    "                print(f\"  运行 {i+1}/{num_runs}: {elapsed_time:.2f}s, {tokens} tokens\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  运行 {i+1}/{num_runs} 失败: {str(e)}\")\n",
    "            \n",
    "            # 在运行之间添加短暂延迟\n",
    "            await asyncio.sleep(1)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    async def compare_models(self, prompts: List[str], num_runs: int = 5) -> pd.DataFrame:\n",
    "        \"\"\"比较多个模型的性能\"\"\"\n",
    "        all_results = []\n",
    "        \n",
    "        for prompt in prompts:\n",
    "            print(f\"\\n测试提示: '{prompt[:50]}...'\")\n",
    "            \n",
    "            prompt_results = {\"prompt\": prompt}\n",
    "            \n",
    "            # 为每个模型运行测试\n",
    "            tasks = []\n",
    "            for model_name in self.models.keys():\n",
    "                task = self.test_single_model(model_name, prompt, num_runs)\n",
    "                tasks.append(task)\n",
    "            \n",
    "            model_results = await asyncio.gather(*tasks)\n",
    "            \n",
    "            # 处理结果\n",
    "            for result in model_results:\n",
    "                model_name = result[\"model\"]\n",
    "                if result[\"success_count\"] > 0:\n",
    "                    avg_time = result[\"total_time\"] / result[\"success_count\"]\n",
    "                    avg_throughput = result[\"total_tokens\"] / result[\"total_time\"] if result[\"total_time\"] > 0 else 0\n",
    "                    \n",
    "                    prompt_results[f\"{model_name}_avg_time\"] = avg_time\n",
    "                    prompt_results[f\"{model_name}_avg_throughput\"] = avg_throughput\n",
    "                    prompt_results[f\"{model_name}_success_rate\"] = result[\"success_count\"] / num_runs\n",
    "                else:\n",
    "                    prompt_results[f\"{model_name}_avg_time\"] = None\n",
    "                    prompt_results[f\"{model_name}_avg_throughput\"] = None\n",
    "                    prompt_results[f\"{model_name}_success_rate\"] = 0\n",
    "            \n",
    "            all_results.append(prompt_results)\n",
    "        \n",
    "        return pd.DataFrame(all_results)\n",
    "    \n",
    "    def generate_report(self, results_df: pd.DataFrame) -> str:\n",
    "        \"\"\"生成性能比较报告\"\"\"\n",
    "        report = []\n",
    "        report.append(\"=\" * 60)\n",
    "        report.append(\"大语言模型推理速度比较报告\")\n",
    "        report.append(\"=\" * 60)\n",
    "        \n",
    "        for index, row in results_df.iterrows():\n",
    "            report.append(f\"\\n提示 {index + 1}: '{row['prompt'][:50]}...'\")\n",
    "            report.append(\"-\" * 40)\n",
    "            \n",
    "            for model_name in self.models.keys():\n",
    "                if f\"{model_name}_avg_time\" in row:\n",
    "                    report.append(\n",
    "                        f\"{model_name}: \"\n",
    "                        f\"{row[f'{model_name}_avg_time']:.2f}s, \"\n",
    "                        f\"{row[f'{model_name}_avg_throughput']:.1f} tokens/s, \"\n",
    "                        f\"成功率: {row[f'{model_name}_success_rate']:.0%}\"\n",
    "                    )\n",
    "        \n",
    "        # 计算总体平均值\n",
    "        report.append(\"\\n\" + \"=\" * 60)\n",
    "        report.append(\"总体性能比较\")\n",
    "        report.append(\"=\" * 60)\n",
    "        \n",
    "        for model_name in self.models.keys():\n",
    "            time_col = f\"{model_name}_avg_time\"\n",
    "            throughput_col = f\"{model_name}_avg_throughput\"\n",
    "            \n",
    "            if time_col in results_df.columns:\n",
    "                avg_time = results_df[time_col].mean()\n",
    "                avg_throughput = results_df[throughput_col].mean()\n",
    "                report.append(f\"{model_name}: 平均响应时间 {avg_time:.2f}s, 平均吞吐量 {avg_throughput:.1f} tokens/s\")\n",
    "        \n",
    "        return \"\\n\".join(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3ce4b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始模型性能比较测试...\n",
      "\n",
      "测试提示: '请解释一下机器学习的基本概念...'\n",
      "正在测试模型: qwen3\n",
      "hhhhhhh\n",
      "请解释一下机器学习的基本概念\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='请解释一下机器学习的基本概念')])]\n",
      "qqqqq\n",
      "正在测试模型: qwen3-vllm\n",
      "hhhhhhh\n",
      "请解释一下机器学习的基本概念\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='请解释一下机器学习的基本概念')])]\n",
      "qqqqq\n",
      "  运行 1/3: 25.80s, 174 tokens\n",
      "hhhhhhh\n",
      "请解释一下机器学习的基本概念\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='请解释一下机器学习的基本概念')])]\n",
      "qqqqq\n",
      "  运行 1/3: 30.91s, 244 tokens\n",
      "hhhhhhh\n",
      "请解释一下机器学习的基本概念\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='请解释一下机器学习的基本概念')])]\n",
      "qqqqq\n",
      "  运行 2/3: 28.87s, 236 tokens\n",
      "hhhhhhh\n",
      "请解释一下机器学习的基本概念\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='请解释一下机器学习的基本概念')])]\n",
      "qqqqq\n",
      "  运行 2/3: 30.47s, 207 tokens\n",
      "hhhhhhh\n",
      "请解释一下机器学习的基本概念\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='请解释一下机器学习的基本概念')])]\n",
      "qqqqq\n",
      "  运行 3/3: 27.83s, 220 tokens\n",
      "  运行 3/3: 30.43s, 240 tokens\n",
      "\n",
      "测试提示: '写一个关于人工智能的短故事...'\n",
      "正在测试模型: qwen3\n",
      "hhhhhhh\n",
      "写一个关于人工智能的短故事\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='写一个关于人工智能的短故事')])]\n",
      "qqqqq\n",
      "正在测试模型: qwen3-vllm\n",
      "hhhhhhh\n",
      "写一个关于人工智能的短故事\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='写一个关于人工智能的短故事')])]\n",
      "qqqqq\n",
      "  运行 1/3: 12.11s, 13 tokens\n",
      "hhhhhhh\n",
      "写一个关于人工智能的短故事\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='写一个关于人工智能的短故事')])]\n",
      "qqqqq\n",
      "  运行 1/3: 14.23s, 18 tokens\n",
      "hhhhhhh\n",
      "写一个关于人工智能的短故事\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='写一个关于人工智能的短故事')])]\n",
      "qqqqq\n",
      "  运行 2/3: 12.66s, 22 tokens\n",
      "hhhhhhh\n",
      "写一个关于人工智能的短故事\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='写一个关于人工智能的短故事')])]\n",
      "qqqqq\n",
      "  运行 2/3: 13.21s, 23 tokens\n",
      "hhhhhhh\n",
      "写一个关于人工智能的短故事\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='写一个关于人工智能的短故事')])]\n",
      "qqqqq\n",
      "  运行 3/3: 11.55s, 19 tokens\n",
      "  运行 3/3: 12.55s, 22 tokens\n",
      "\n",
      "测试提示: '如何提高编程技能？请给出具体建议...'\n",
      "正在测试模型: qwen3\n",
      "hhhhhhh\n",
      "如何提高编程技能？请给出具体建议\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='如何提高编程技能？请给出具体建议')])]\n",
      "qqqqq\n",
      "正在测试模型: qwen3-vllm\n",
      "hhhhhhh\n",
      "如何提高编程技能？请给出具体建议\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='如何提高编程技能？请给出具体建议')])]\n",
      "qqqqq\n",
      "  运行 1/3: 32.56s, 287 tokens\n",
      "hhhhhhh\n",
      "如何提高编程技能？请给出具体建议\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='如何提高编程技能？请给出具体建议')])]\n",
      "qqqqq\n",
      "  运行 1/3: 38.32s, 317 tokens\n",
      "hhhhhhh\n",
      "如何提高编程技能？请给出具体建议\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='如何提高编程技能？请给出具体建议')])]\n",
      "qqqqq\n",
      "  运行 2/3: 34.13s, 289 tokens\n",
      "hhhhhhh\n",
      "如何提高编程技能？请给出具体建议\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='如何提高编程技能？请给出具体建议')])]\n",
      "qqqqq\n",
      "  运行 2/3: 34.13s, 318 tokens\n",
      "hhhhhhh\n",
      "如何提高编程技能？请给出具体建议\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='如何提高编程技能？请给出具体建议')])]\n",
      "qqqqq\n",
      "  运行 3/3: 35.71s, 316 tokens\n",
      "  运行 3/3: 41.98s, 322 tokens\n",
      "\n",
      "测试提示: '用Python写一个快速排序算法...'\n",
      "正在测试模型: qwen3\n",
      "hhhhhhh\n",
      "用Python写一个快速排序算法\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='用Python写一个快速排序算法')])]\n",
      "qqqqq\n",
      "正在测试模型: qwen3-vllm\n",
      "hhhhhhh\n",
      "用Python写一个快速排序算法\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='用Python写一个快速排序算法')])]\n",
      "qqqqq\n",
      "  运行 1/3: 12.11s, 136 tokens\n",
      "hhhhhhh\n",
      "用Python写一个快速排序算法\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='用Python写一个快速排序算法')])]\n",
      "qqqqq\n",
      "  运行 1/3: 15.25s, 195 tokens\n",
      "hhhhhhh\n",
      "用Python写一个快速排序算法\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='用Python写一个快速排序算法')])]\n",
      "qqqqq\n",
      "  运行 2/3: 11.06s, 128 tokens\n",
      "hhhhhhh\n",
      "用Python写一个快速排序算法\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='用Python写一个快速排序算法')])]\n",
      "qqqqq\n",
      "  运行 2/3: 12.11s, 134 tokens\n",
      "hhhhhhh\n",
      "用Python写一个快速排序算法\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='用Python写一个快速排序算法')])]\n",
      "qqqqq\n",
      "  运行 3/3: 11.06s, 129 tokens\n",
      "  运行 3/3: 14.21s, 170 tokens\n",
      "\n",
      "测试提示: '谈谈气候变化对全球经济的影响...'\n",
      "正在测试模型: qwen3\n",
      "hhhhhhh\n",
      "谈谈气候变化对全球经济的影响\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='谈谈气候变化对全球经济的影响')])]\n",
      "qqqqq\n",
      "正在测试模型: qwen3-vllm\n",
      "hhhhhhh\n",
      "谈谈气候变化对全球经济的影响\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='谈谈气候变化对全球经济的影响')])]\n",
      "qqqqq\n",
      "  运行 1/3: 24.17s, 95 tokens\n",
      "hhhhhhh\n",
      "谈谈气候变化对全球经济的影响\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='谈谈气候变化对全球经济的影响')])]\n",
      "qqqqq\n",
      "  运行 1/3: 25.21s, 95 tokens\n",
      "hhhhhhh\n",
      "谈谈气候变化对全球经济的影响\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='谈谈气候变化对全球经济的影响')])]\n",
      "qqqqq\n",
      "  运行 2/3: 27.30s, 109 tokens\n",
      "hhhhhhh\n",
      "谈谈气候变化对全球经济的影响\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='谈谈气候变化对全球经济的影响')])]\n",
      "qqqqq\n",
      "  运行 2/3: 27.84s, 109 tokens\n",
      "hhhhhhh\n",
      "谈谈气候变化对全球经济的影响\n",
      "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='你是一个有帮助的AI助手。')]), ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='谈谈气候变化对全球经济的影响')])]\n",
      "qqqqq\n",
      "  运行 3/3: 23.68s, 88 tokens\n",
      "  运行 3/3: 25.22s, 95 tokens\n",
      "============================================================\n",
      "大语言模型推理速度比较报告\n",
      "============================================================\n",
      "\n",
      "提示 1: '请解释一下机器学习的基本概念...'\n",
      "----------------------------------------\n",
      "qwen3: 27.50s, 7.6 tokens/s, 成功率: 100%\n",
      "qwen3-vllm: 30.60s, 7.5 tokens/s, 成功率: 100%\n",
      "\n",
      "提示 2: '写一个关于人工智能的短故事...'\n",
      "----------------------------------------\n",
      "qwen3: 12.11s, 1.5 tokens/s, 成功率: 100%\n",
      "qwen3-vllm: 13.33s, 1.6 tokens/s, 成功率: 100%\n",
      "\n",
      "提示 3: '如何提高编程技能？请给出具体建议...'\n",
      "----------------------------------------\n",
      "qwen3: 36.05s, 8.8 tokens/s, 成功率: 100%\n",
      "qwen3-vllm: 36.22s, 8.3 tokens/s, 成功率: 100%\n",
      "\n",
      "提示 4: '用Python写一个快速排序算法...'\n",
      "----------------------------------------\n",
      "qwen3: 11.41s, 11.5 tokens/s, 成功率: 100%\n",
      "qwen3-vllm: 13.85s, 12.0 tokens/s, 成功率: 100%\n",
      "\n",
      "提示 5: '谈谈气候变化对全球经济的影响...'\n",
      "----------------------------------------\n",
      "qwen3: 25.05s, 3.9 tokens/s, 成功率: 100%\n",
      "qwen3-vllm: 26.09s, 3.8 tokens/s, 成功率: 100%\n",
      "\n",
      "============================================================\n",
      "总体性能比较\n",
      "============================================================\n",
      "qwen3: 平均响应时间 22.42s, 平均吞吐量 6.7 tokens/s\n",
      "qwen3-vllm: 平均响应时间 24.02s, 平均吞吐量 6.6 tokens/s\n",
      "\n",
      "详细结果已保存到 model_benchmark_results.csv\n"
     ]
    }
   ],
   "source": [
    "    # 配置你的模型\n",
    "model_configs = {\n",
    "    \"qwen3\": {\n",
    "        \"api_base\": \"http://192.168.100.30:16001/v1\",\n",
    "        \"api_key\": \"empty\"\n",
    "    },\n",
    "    \"qwen3-vllm\": {\n",
    "        \"api_base\": \"http://192.168.100.30:16002/v1\",\n",
    "        \"api_key\": \"empty\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# 测试提示语\n",
    "test_prompts = [\n",
    "    \"请解释一下机器学习的基本概念\",\n",
    "    \"写一个关于人工智能的短故事\",\n",
    "    \"如何提高编程技能？请给出具体建议\",\n",
    "    \"用Python写一个快速排序算法\",\n",
    "    \"谈谈气候变化对全球经济的影响\"\n",
    "]\n",
    "\n",
    "# 创建基准测试实例\n",
    "benchmark = ModelBenchmark(model_configs)\n",
    "\n",
    "# 运行测试\n",
    "print(\"开始模型性能比较测试...\")\n",
    "results = await benchmark.compare_models(test_prompts, num_runs=3)\n",
    "\n",
    "# 生成报告\n",
    "report = benchmark.generate_report(results)\n",
    "print(report)\n",
    "\n",
    "# 保存结果到CSV\n",
    "results.to_csv(\"model_benchmark_results.csv\", index=False)\n",
    "print(\"\\n详细结果已保存到 model_benchmark_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
